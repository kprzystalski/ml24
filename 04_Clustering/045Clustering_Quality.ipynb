{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering quality metrics\n",
    "\n",
    "We can divide the clustering quality metrics into two groups: internal and external indicies. Internal indicies base only on the the clustered data without a clustered version that we could benchmark with. In other words, we don't have labelled/clustered data to compare with. In external indicies we have the information about the expected output and we are able to calculate metrics like accuracy, f1-score and other known from supervised learning.\n",
    "\n",
    "In this section we focus on internal indicies only. We can group internal indicies into two groups:\n",
    "- heterogeneity,\n",
    "- homogeneity.\n",
    "Four heterogeneity and two homogeneity methods are presented in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "Clustering quality metrics are implemented using only two libraries: ``numpy`` and ``math``, where the second one is used calculate the Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_distance(x,v):\n",
    "    return sqrt((x[0]-v[0])**2+(x[1]-v[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "We compare two data sets, both are a results of HCM method. The first one is a HCM that divided the data set into two groups. We just restore the variable ``new_assignation_hcm`` and ``new_centers_hcm``. We have set two other variable of possible clustering for three groups and saved the results in ``new_assignation_hcm3`` and ``new_centers_hcm3``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r new_assignation_hcm\n",
    "%store -r new_centers_hcm\n",
    "%store -r data_set\n",
    "\n",
    "new_assignation_hcm = np.array(new_assignation_hcm)\n",
    "new_centers_hcm = np.array(new_centers_hcm)\n",
    "\n",
    "new_assignation_hcm3 = np.array([[0., 1., 0.],[0., 1., 0.], [0., 1., 0.],[0., 1., 0.], [0., 1., 0.], [0., 1., 0.], [0., 0., 1.], [0., 0., 1.], [0., 0., 1.], [1., 0., 0.]])\n",
    "new_centers_hcm3 = np.array([[0.42239686, 0.38503185],[0.07858546, 0.17832272],[0.82907662, 0.97059448]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneity and heterogeneity\n",
    "\n",
    "We have four separation measures $s_{1}(c_{i},c_{j})$, $s_{2}(c_{i},c_{j})$,\n",
    "$s(s_{1})$ and $s(s_{2})$. The first two separation measures explain how far from each other the clusters are. We take the objects in each cluster and measure the distances between each object of two different clusters. \n",
    "\n",
    "The metric $s_{1}$ can be calculate as following:\n",
    "\\begin{equation}\n",
    " s_{1}(c_{i},c_{j})=\\frac{1}{n_{i}n_{j}}\\sqrt{\\sum_{x_{1},\\in c_{i},x_{2}\\in c_{j}}d^{2}(x_{1},x_{2})}.\n",
    "\\end{equation}\n",
    "This measure can be implemented as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_s_1(centers,assignation):\n",
    "    s1 = []\n",
    "    for center_1 in range(len(centers)):\n",
    "        for center_2 in range(len(centers)):\n",
    "            if center_1 == center_2:\n",
    "                break\n",
    "            ids_1 = np.where(assignation[:, center_1] == 1)[0]\n",
    "            ids_2 = np.where(assignation[:, center_2] == 1)[0]\n",
    "            elements_1 = data_set[ids_1]\n",
    "            elements_2 = data_set[ids_2]\n",
    "            s_1 = 1.0 / (len(ids_1) * len(ids_2))\n",
    "            for element_1 in elements_1:\n",
    "                for element_2 in elements_2:\n",
    "                    s_1 = s_1 * sqrt(calculate_distance(element_1, element_2) ** 2)\n",
    "            s1.append(s_1)\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take two objects, each from different cluster and calculate the power distance measure. Next, we sum all the distances from object of two clusters and calculate a square root of it. The value is then divided by the multiplication of the counts of objects in both clusters. The higher value is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10062820443387574]\n",
      "[0.0007587103186922478, 0.12913857784026206, 0.3030325350305444]\n"
     ]
    }
   ],
   "source": [
    "s1_2 = calculate_s_1(new_centers_hcm,new_assignation_hcm)\n",
    "s1_3 = calculate_s_1(new_centers_hcm3,new_assignation_hcm3)\n",
    "\n",
    "print(s1_2)\n",
    "print(s1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best clusters are the first compared to the second in the thre group clustering. \n",
    "\n",
    "The second separation measure is about the distance between two centers only:\n",
    "\\begin{equation}\n",
    " s_{2}(c_{i},c_{j})=d(c_{i},c_{j}).\n",
    "\\end{equation}\n",
    "It is the simplest measure and it can be implemented as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_s_2(centers):\n",
    "    s2 = []\n",
    "    for center_1 in range(len(centers)):\n",
    "        for center_2 in range(len(centers)):\n",
    "            if center_1 == center_2:\n",
    "                break\n",
    "            s2.append(calculate_distance(centers[center_1], centers[center_2]))\n",
    "    return s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same as the previous metric, higher values means a better cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0361961303876361]\n",
      "[0.40116697670087065, 0.7129319889345509, 1.0912980907761376]\n"
     ]
    }
   ],
   "source": [
    "s2_2 = calculate_s_2(new_centers_hcm)\n",
    "s2_3 = calculate_s_2(new_centers_hcm3)\n",
    "\n",
    "print(s2_2)\n",
    "print(s2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different metric is the $\\sigma_{1}$ which does not take the centers into consideration. It measures the distances between each object within a cluster. The smaller value here the better cluster it is. The metric is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    " \\sigma_{1}(c_{i})=\\frac{1}{m}\\sum_{x_{1}, x_{2}\\in c_{i}}d^{2}(x_{1},x_{2}),\n",
    "\\end{equation}\n",
    "\n",
    "where the $m$ is defined as \n",
    "\n",
    "\\begin{equation}\n",
    " m=\\frac{(n_{i}-1)n_{i}}{2}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sigma_1(assignation):\n",
    "    sigma_1 = []\n",
    "    unique_labels = len(assignation[0])\n",
    "    for label_id in range(unique_labels):\n",
    "        ids = np.where(assignation[:, label_id] == 1)[0]\n",
    "        if len(ids) == 1:\n",
    "            sigma_1.append(1.0)\n",
    "            continue\n",
    "        else:\n",
    "            m = (len(ids) - 1.0) * len(ids) / 2.0\n",
    "        elements = data_set[ids]\n",
    "        sigma = (1.0 / m)\n",
    "        for element_x_1 in range(len(elements)):\n",
    "            for element_x_2 in range(len(elements)):\n",
    "                if element_x_1 == element_x_2:\n",
    "                    continue\n",
    "                distance = calculate_distance(elements[element_x_1], elements[element_x_2])\n",
    "                if distance != 0:\n",
    "                    sigma = sigma + (distance ** 2)\n",
    "        sigma_1.append(sigma)\n",
    "    return sigma_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are given for each cluster. That's why we have only two values in the first cases, and three in the second list. Lower value means a better cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.775635895144805, 0.9686234538734891]\n",
      "[1.0, 0.7496360155982489, 0.9686234538734891]\n"
     ]
    }
   ],
   "source": [
    "sigma1_2 = calculate_sigma_1(new_assignation_hcm)\n",
    "sigma1_3 = calculate_sigma_1(new_assignation_hcm3)\n",
    "\n",
    "print(sigma1_2)\n",
    "print(sigma1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the metric $s(s_{1})$ we take two previously calculated values:\n",
    "\\begin{equation}\n",
    " s(s_{1})=\\sum_{i,j=1;j\\neq i}^{K}\\frac{s_{1}(c_{i},c_{j})}{\\sigma_{1}(c_{i})}.\n",
    "\\end{equation}\n",
    "This measure is a bit more complex and it measure the relation between the distances of objects within a cluster and distnaces between objects in two clusters. Higher values means a better cluster, but it takes the relation between two clusters as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_s_s_1(s1, sigma_1):\n",
    "    s_1_sum = 0.0\n",
    "    sigma_1_sum = 0.0\n",
    "    for s_1 in s1:\n",
    "        s_1_sum = s_1_sum + s_1\n",
    "    for sigma_1 in sigma_1:\n",
    "        sigma_1_sum = sigma_1_sum + sigma_1\n",
    "    s_s1 = s_1_sum / sigma_1_sum\n",
    "    return s_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results below makes it clear that three clusters solution is better than two. Usually it is that increasing the number of clusters increase the value of this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026875329685765333\n",
      "0.1592672914604556\n"
     ]
    }
   ],
   "source": [
    "s11_2 = calculate_s_s_1(s1_2,sigma1_2)\n",
    "s11_3 = calculate_s_s_1(s1_3,sigma1_3)\n",
    "\n",
    "print(s11_2)\n",
    "print(s11_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric $\\sigma_{2}$ measures the distances between objects within a cluster and the center of this cluster. It is defined as:\n",
    "\\begin{equation}\n",
    " \\sigma_{2}(c_{i})=\\frac{1}{n_{i}}\\sum_{x\\in c_{i}}d^{2}(x,c_{i}).\n",
    "\\end{equation}\n",
    "It can be implemented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sigma_2(centers,assignation):\n",
    "    sigma_2 = []\n",
    "    for center_id in range(len(centers)):\n",
    "        ids = np.where(assignation[:, center_id] == 1)[0]\n",
    "        elements = data_set[ids]\n",
    "        sigma = 1.0 / len(ids)\n",
    "        for element_id in range(len(elements)):\n",
    "            distance = calculate_distance(elements[element_id], centers[center_id])\n",
    "            if distance != 0:\n",
    "                sigma = sigma + (distance) ** 2\n",
    "        sigma_2.append(sigma)\n",
    "    return sigma_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower value means a better cluster. We get a list of values for each cluster. In our case the second cluster in the three cluster approach is the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3377154891089826, 0.4392150200900259]\n",
      "[1.0, 0.22358077907763185, 0.4392150200900259]\n"
     ]
    }
   ],
   "source": [
    "sigma2_2 = calculate_sigma_2(new_centers_hcm,new_assignation_hcm)\n",
    "sigma2_3 = calculate_sigma_2(new_centers_hcm3,new_assignation_hcm3)\n",
    "\n",
    "print(sigma2_2)\n",
    "print(sigma2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other internal indices\n",
    "\n",
    "The Dunn index says what is the relation between the minimal distance of objects within a cluster and the maximum distance of objects within a cluster. It gives a better understanding of how far are the objects from each other. It can be easily calculated as a quotient of two distances:\n",
    "\\begin{equation}\n",
    " C=\\frac{d_{min}}{d_{max}},\n",
    "\\end{equation}\n",
    "where the equations of $d_{max}$ and $d_{min}$ are like following:\n",
    "\\begin{equation}\n",
    " d_{max}=\\max_{1\\leq k\\leq K}D_{k},\\\\\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    " d_{min}=\\min_{k\\neq k'} d_{k}.\n",
    "\\end{equation}\n",
    "\n",
    "Both distances are just the minimum and maximum euclidean distances between objects. The minimum distance is a measure of two object that are in different clusters:\n",
    "\\begin{equation}\n",
    " d_{k}=\\min_{i,j\\in I_{k}; i\\neq j}d(x_{i}^{(k)}-x_{j}^{(k')}).\n",
    "\\end{equation}\n",
    "The clusters are marked with $k$ and $k'$. The maximum distance takes the distance of two objects within a cluster:\n",
    "\\begin{equation}\n",
    " D_{k}=\\max_{i,j\\in I_{k}; i\\neq j}d(x_{i}^{(k)}-x_{j}^{(k)}).\n",
    "\\end{equation}\n",
    "It can be implemeneted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index(assignation):\n",
    "    minimum_distance = 1\n",
    "    maximum_distance = 0\n",
    "    unique_labels = np.unique(assignation[0])\n",
    "    for label_id_1 in range(len(unique_labels)):\n",
    "        ids_1 = np.where(assignation[:, label_id_1] == 1)[0]\n",
    "        for label_id_2 in range(len(unique_labels)):\n",
    "            if label_id_1 == label_id_2:\n",
    "                break\n",
    "            ids_2 = np.where(assignation[:, label_id_2] == 1)[0]\n",
    "            for element_1 in data_set[ids_1]:\n",
    "                for element_2 in data_set[ids_2]:\n",
    "                    distance = calculate_distance(element_1, element_2)\n",
    "                    if distance > maximum_distance:\n",
    "                        maximum_distance = distance\n",
    "                    if distance < minimum_distance:\n",
    "                        minimum_distance = distance\n",
    "    dunn_index = minimum_distance / maximum_distance\n",
    "    return dunn_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of Dunn index for our examples are given below. In this case a higher values means a better clustering result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48534159949891914\n",
      "0.7224828783672833\n"
     ]
    }
   ],
   "source": [
    "dunn2 = dunn_index(new_assignation_hcm)\n",
    "dunn3 = dunn_index(new_assignation_hcm3)\n",
    "\n",
    "print(dunn2)\n",
    "print(dunn3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

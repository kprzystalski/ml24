{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density-based clustering\n",
    "\n",
    "In density-based clustering the approach is different compared to distributed clustering. We need to implement all functions from scratch. The libraries that we are going to use are the same as in previous example, but in this case we have also the random package that is used to shuffle the objects in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBScan is an example of a density-based clustering method. The goal is to find all element where the neighborhood is defined as:\n",
    "\\begin{equation}\n",
    "    N_{\\epsilon}:{q|d(p,q)\\leq\\epsilon},\n",
    "\\end{equation}\n",
    "where $p$ and $q$ are two elements of the training data set and $\\epsilon$ is the neighborhood distance. For the data set used before and $\\epsilon$ to 0.25 we get the regions like in figure below.\n",
    "\n",
    "![density](./../images/density.png)\n",
    "\n",
    "Let's setup the variables as in previous examples. The are three new ones like ```distance_matrix```, ```max_distance```, ```number_of_cluster```, and ``min_points``. The first one is clear, the second is a parameter that can be changed, depending on that how many neighborhood elements we would like to concider. The next variable is about the number of clusters that are calculated during clustering. It's not the exact number of clusters, but allow us count the clusters during clustering. Last variable is the number of points that needs to within a neighbourhood to be classified as non-border object. Boarded points are the points that are the farest points from the cluster, but it's not the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_set\n",
    "\n",
    "assignation = np.zeros(len(data_set))\n",
    "distance_matrix = np.zeros((len(data_set), len(data_set)))\n",
    "max_distance = 0.25\n",
    "number_of_cluster = 0\n",
    "min_points = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the distance function that we used in previous example to calculate the distance matrix:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(x,v):\n",
    "    return sqrt((x[0]-v[0])**2+(x[1]-v[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the distance matrix we use the calculate_distance that we used previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix():\n",
    "    distance_matrix = np.zeros((len(data_set),len(data_set)))\n",
    "    for i in range(len(data_set)):\n",
    "        for j in range(len(data_set)):\n",
    "            distance_matrix[i, j] = calculate_distance(data_set[i], data_set[j])\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get closest elements in the feature space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_elements(distance_matrix, element_id):\n",
    "    element_distances = distance_matrix[element_id]\n",
    "    filtered = {}\n",
    "    iter = 0\n",
    "    for element in element_distances:\n",
    "        if element < max_distance:\n",
    "            filtered[iter] = element\n",
    "        iter = iter + 1\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step before cluster function is to define funtions that mark the elements in our data set that are known to be a noise or were already visited by our method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_as_noise(assignation,element_id):\n",
    "    assignation[element_id] = -1\n",
    "    return assignation\n",
    "    \n",
    "def set_visited(elements, assignation, number_of_clusters):    \n",
    "    for element_id in elements.keys():\n",
    "        assignation[element_id] = number_of_clusters \n",
    "    return assignation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_density(assignation):\n",
    "    number_of_cluster = 0\n",
    "    distance_matrix = calculate_distance_matrix()\n",
    "    element_ids = list(range(len(data_set)))\n",
    "    random.shuffle(element_ids)\n",
    "    for i in element_ids:\n",
    "        if assignation[i] != 0:\n",
    "            continue\n",
    "        closest = get_closest_elements(distance_matrix, i)\n",
    "        if len(closest) < min_points:\n",
    "            assignation = set_as_noise(assignation,i)\n",
    "        else:\n",
    "            assignation = set_visited(closest, assignation, number_of_cluster)\n",
    "            number_of_cluster = number_of_cluster + 1\n",
    "    return assignation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready to cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_assignation_density = cluster_density(assignation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of cluster is the size of unique cluster ids that are in ``new_assignation_density`` minus noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of clusters: \"+ str(len(np.unique(new_assignation_density))-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise is marked with -1. The other objects have the cluster number assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.  2.  1.  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(new_assignation_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'new_assignation_density' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store new_assignation_density"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

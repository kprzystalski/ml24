{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernels\n",
    "\n",
    "In some cases the problem is that we are looking for a linear boundary when the boundary in our space is non-linear. However is does not mean that there is no space in which this problem have no linear boundary. If we find the mapping to such space the problem could be solved. \n",
    "\n",
    "The question is if we can map the features space into more dimensions in such a way to make the problem linearly separable. Is is quite obvious that if we will use the function:\n",
    "\\begin{equation}\n",
    "K(x) = (x_1^2, \\sqrt(2) x_1 x_2, x_2^2)\n",
    "\\end{equation}\n",
    "then we transfer our problem into $R^3$ space in which it is linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data set in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cvxopt\n",
    "\n",
    "iris = load_iris()\n",
    "data_set = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "data_set = data_set[labels!=2]\n",
    "labels = labels[labels!=2]\n",
    "\n",
    "train_data_set, test_data_set, train_labels, test_labels = train_test_split(\n",
    "    data_set, labels, test_size=0.2, random_state=15)\n",
    "\n",
    "train_labels[train_labels<1] = -1\n",
    "test_labels[test_labels<1] = -1\n",
    "\n",
    "objects_count = len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``build_kernel`` function for building more than just the linear kernel needs to be modifier. The RBF kernel can be written as:\n",
    "\\begin{equation}\n",
    "K=\\exp(-\\frac{|x-x'|^{2}}{2\\sigma^{2}})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kernel(data_set, kernel_type='linear'):\n",
    "    kernel = np.dot(data_set, data_set.T)\n",
    "    if kernel_type == 'rbf':\n",
    "        sigma = 1.0\n",
    "        objects_count = len(data_set)\n",
    "        b = np.ones((len(data_set), 1))\n",
    "        kernel -= 0.5 * (np.dot((np.diag(kernel)*np.ones((1, objects_count))).T, b.T)\n",
    "                         + np.dot(b, (np.diag(kernel) * np.ones((1, objects_count))).T.T))\n",
    "        kernel = np.exp(kernel / (2. * sigma ** 2))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training part is the same as in the case of linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_set, train_labels, kernel_type='linear', C=10, threshold=1e-5):\n",
    "    kernel = build_kernel(train_data_set, kernel_type=kernel_type)\n",
    "\n",
    "    P = train_labels * train_labels.transpose() * kernel\n",
    "    q = -np.ones((objects_count, 1))\n",
    "    G = np.concatenate((np.eye(objects_count), -np.eye(objects_count)))\n",
    "    h = np.concatenate((C * np.ones((objects_count, 1)), np.zeros((objects_count, 1))))\n",
    "\n",
    "    A = train_labels.reshape(1, objects_count)\n",
    "    A = A.astype(float)\n",
    "    b = 0.0\n",
    "\n",
    "    sol = cvxopt.solvers.qp(cvxopt.matrix(P), cvxopt.matrix(q), cvxopt.matrix(G), cvxopt.matrix(h), cvxopt.matrix(A), cvxopt.matrix(b))\n",
    "\n",
    "    lambdas = np.array(sol['x'])\n",
    "\n",
    "    support_vectors_id = np.where(lambdas > threshold)[0]\n",
    "    vector_number = len(support_vectors_id)\n",
    "    support_vectors = train_data_set[support_vectors_id, :]\n",
    "\n",
    "    lambdas = lambdas[support_vectors_id]\n",
    "    targets = train_labels[support_vectors_id]\n",
    "\n",
    "    b = np.sum(targets)\n",
    "    for n in range(vector_number):\n",
    "        b -= np.sum(lambdas * targets * np.reshape(kernel[support_vectors_id[n], support_vectors_id], (vector_number, 1)))\n",
    "    b /= len(lambdas)\n",
    "\n",
    "    return lambdas, support_vectors, support_vectors_id, b, targets, vector_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction part is a bit different as we need to take RBF kernel into consideration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rbf(test_data_set, train_data_set, lambdas, targets, b, vector_number, support_vectors, support_vectors_id):\n",
    "    kernel = np.dot(test_data_set, support_vectors.T)\n",
    "    sigma = 1.0\n",
    "    c = (1. / sigma * np.sum(test_data_set ** 2, axis=1) * np.ones((1, np.shape(test_data_set)[0]))).T\n",
    "    c = np.dot(c, np.ones((1, np.shape(kernel)[1])))\n",
    "    sv = (np.diag(np.dot(train_data_set, train_data_set.T))*np.ones((1,len(train_data_set)))).T[support_vectors_id]\n",
    "    aa = np.dot(sv,np.ones((1,np.shape(kernel)[0]))).T\n",
    "    kernel = kernel - 0.5 * c - 0.5 * aa\n",
    "    kernel = np.exp(kernel / (2. * sigma ** 2))\n",
    "\n",
    "    y = np.zeros((np.shape(test_data_set)[0], 1))\n",
    "    for j in range(np.shape(test_data_set)[0]):\n",
    "        for i in range(vector_number):\n",
    "            y[j] += lambdas[i] * targets[i] * kernel[j, i]\n",
    "        y[j] += b\n",
    "    return np.sign(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction and accuracy is usually higher than the linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  9.6305e+01 -1.2289e+03  2e+03  2e-01  2e-15\n",
      " 1:  5.9143e+01 -1.2031e+02  2e+02  5e-03  2e-15\n",
      " 2:  7.0898e+00 -1.6497e+01  2e+01  3e-16  2e-15\n",
      " 3: -5.2057e-01 -3.7668e+00  3e+00  2e-16  8e-16\n",
      " 4: -1.1712e+00 -1.8374e+00  7e-01  2e-16  3e-16\n",
      " 5: -1.3952e+00 -1.6846e+00  3e-01  2e-16  2e-16\n",
      " 6: -1.4671e+00 -1.5679e+00  1e-01  2e-16  2e-16\n",
      " 7: -1.5060e+00 -1.5164e+00  1e-02  2e-16  2e-16\n",
      " 8: -1.5105e+00 -1.5106e+00  1e-04  2e-16  2e-16\n",
      " 9: -1.5105e+00 -1.5105e+00  1e-06  2e-16  2e-16\n",
      "Optimal solution found.\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "lambdas, support_vectors, support_vectors_id, b, targets, vector_number = train(train_data_set, train_labels, kernel_type='rbf')\n",
    "predicted = classify_rbf(test_data_set, train_data_set, lambdas, targets, b, vector_number, support_vectors, support_vectors_id)\n",
    "predicted = list(predicted.astype(int))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(predicted, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
